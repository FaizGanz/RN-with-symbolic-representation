{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1p6IcmH7PPdbg5LDlFUmIa2-KGZCyGAFe","timestamp":1670722955026}],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"premium"},"cells":[{"cell_type":"markdown","source":["## Part 1: Model Explanation\n","\n","Simple relational inferences have proved challenging through simple black-box architectures such as MLPs, CNNs, RNNs or a combination of them. A solution to this problem is the implementation of Relational Network modules throughout the selected base architecture.\n","\n","A Relational network is a neural network module that is used to model relational reasoning. The idea behind Relational networks is to use general-purpose components (MLPs) so that we can capture the patterns of relational properties and use them to augment the network architecture by modulating the upstream representations (feature maps).\n","\n","RN Module:\n","\n","$RN(O) = f_ϕ(\\sum_{i,j} g_\\theta (o_i, o_j))$\n","\n","The input to the Rn module is the set object $O = \\{o_1, o_2, ..., o_n\\}$, where $o_i ∈ \\mathbb{R}^m$. The functions $f_\\phi$ and $g_\\theta$ are simple MLPs with parameters $\\phi$ and $\\theta$. For each pair of objects $(o_i, o_j)$ the function $g_\\theta$ is tasked with inferring their relationship in an order invariant manner. Because the module is made with general purpose components it is end-to-end differentiable. There is no specific requirement for what an object can be, hence relatively unstructured inputs such as CNN or LSTM embeddings can be used as objects.\n","\n","In reality however, the RN quesiton dependent. Hence the correct formulation is $a = f_ϕ(\\sum_{i,j} g_\\theta (o_i, o_j, q))$.\n","\n","For the Sort-of-CLEVR dataset, the model used does not contain an LSTM portion. The questions are encoded as binary strings embeddings of fixed size which are passed directly to the RN module in combination with the object representations.\n","\n","The model consists of four convolution layers with 32, 64, 128, and 256 kernels coupled with ReLU activation functions and batch-normalization. The RN module is made up by a four layer MLP with 2000 neurons per layer for the function $g_\\theta$ and a four layer MLP with 2000, 1000, 500, and 100 neurons respectively for the function $f_\\phi$.\n","\n","The model is topped with a final classification layer and trained using CE loss and an Adam optimizer with learning rate of $1e-4$.\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"4lb4_Hg_W37L"}},{"cell_type":"markdown","source":["## Part 2: Model Implementation"],"metadata":{"id":"rPB6nNz1XBHr"}},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.autograd import Variable\n","\n","from __future__ import print_function\n","import os\n","import pickle\n","import random\n","import numpy as np\n","import csv\n","\n","import torch\n","from torch.utils.tensorboard import SummaryWriter"],"metadata":{"id":"bQDEEDS92AIE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"khYHkKi-F2Dc","executionInfo":{"status":"ok","timestamp":1670722922822,"user_tz":300,"elapsed":14590,"user":{"displayName":"Faiz Andrea Ganz","userId":"07639753498586550069"}},"outputId":"6193115b-ff5b-4460-9ba2-b5c66918a158"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["%cd '/content/gdrive/MyDrive/ai/finalpj'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bgy84__1F7M6","executionInfo":{"status":"ok","timestamp":1670722922822,"user_tz":300,"elapsed":3,"user":{"displayName":"Faiz Andrea Ganz","userId":"07639753498586550069"}},"outputId":"db9c04ae-b053-49eb-f5cc-271f3832af90"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/ai/finalpj\n"]}]},{"cell_type":"code","source":["class ConvInputModel(nn.Module):\n","    def __init__(self):\n","        super(ConvInputModel, self).__init__()\n","        \n","        self.conv1 = nn.Conv2d(3, 32, 3, stride=2, padding=1)\n","        self.batchNorm1 = nn.BatchNorm2d(32)\n","        self.conv2 = nn.Conv2d(32, 64, 3, stride=2, padding=1)\n","        self.batchNorm2 = nn.BatchNorm2d(64)\n","        self.conv3 = nn.Conv2d(64, 128, 3, stride=2, padding=1)\n","        self.batchNorm3 = nn.BatchNorm2d(128)\n","        self.conv4 = nn.Conv2d(128, 256, 3, stride=2, padding=1)\n","        self.batchNorm4 = nn.BatchNorm2d(256)\n","        \n","    def forward(self, img):\n","        \"\"\"convolution\"\"\"\n","        x = self.conv1(img)\n","        x = F.relu(x)\n","        x = self.batchNorm1(x)\n","        x = self.conv2(x)\n","        x = F.relu(x)\n","        x = self.batchNorm2(x)\n","        x = self.conv3(x)\n","        x = F.relu(x)\n","        x = self.batchNorm3(x)\n","        x = self.conv4(x)\n","        x = F.relu(x)\n","        x = self.batchNorm4(x)\n","        return x"],"metadata":{"id":"hU5RE1F63ZTJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class FCOutputModel(nn.Module):\n","    def __init__(self):\n","        super(FCOutputModel, self).__init__()\n","\n","        self.fc2 = nn.Linear(100, 100)\n","        self.fc3 = nn.Linear(100, 10)\n","\n","    def forward(self, x):\n","        x = self.fc2(x)\n","        x = F.relu(x)\n","        x = F.dropout(x)\n","        x = self.fc3(x)\n","        return F.log_softmax(x, dim=1)"],"metadata":{"id":"vbSHqBOQ5z-H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class BasicModel(nn.Module):\n","    def __init__(self, name, **kwargs):\n","        super(BasicModel, self).__init__()\n","        self.name=name\n","\n","    def train_(self, input_img, input_qst, label):\n","        self.optimizer.zero_grad()\n","        output = self(input_img, input_qst)\n","        loss = F.nll_loss(output, label)\n","        loss.backward()\n","        self.optimizer.step()\n","        pred = output.data.max(1)[1]\n","        correct = pred.eq(label.data).cpu().sum()\n","        accuracy = correct * 100. / len(label)\n","        return accuracy, loss\n","        \n","    def test_(self, input_img, input_qst, label):\n","        output = self(input_img, input_qst)\n","        loss = F.nll_loss(output, label)\n","        pred = output.data.max(1)[1]\n","        correct = pred.eq(label.data).cpu().sum()\n","        accuracy = correct * 100. / len(label)\n","        return accuracy, loss\n","\n","    def save_model(self, epoch):\n","        torch.save(self.state_dict(), 'model/epoch_{}_{:02d}.pth'.format(self.name, epoch))"],"metadata":{"id":"Mvn6fiUJ52_P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class RN(BasicModel):\n","    def __init__(self, **kwargs):\n","        super(RN, self).__init__('RN', **kwargs)\n","        \n","        self.conv = ConvInputModel()\n","        \n","        self.relation_type = kwargs['relation_type']\n","        \n","        if self.relation_type == 'ternary':\n","            ##(number of filters per object+coordinate of object)*3+question vector\n","            self.g_fc1 = nn.Linear((256+2)*3+18, 2000)\n","        else:\n","            ##(number of filters per object+coordinate of object)*2+question vector\n","            self.g_fc1 = nn.Linear((256+2)*2+18, 2000)\n","\n","        self.g_fc2 = nn.Linear(2000, 2000)\n","        self.g_fc3 = nn.Linear(2000, 2000)\n","        self.g_fc4 = nn.Linear(2000, 2000)\n","\n","        self.f_fc1 = nn.Linear(2000, 2000)\n","        self.f_fc2 = nn.Linear(2000, 1000)\n","        self.f_fc3 = nn.Linear(1000, 500)\n","        self.f_fc4 = nn.Linear(500, 100)\n","\n","        self.coord_oi = torch.FloatTensor(kwargs['batch_size'], 2)\n","        self.coord_oj = torch.FloatTensor(kwargs['batch_size'], 2)\n","        if kwargs['cuda']:\n","            self.coord_oi = self.coord_oi.cuda()\n","            self.coord_oj = self.coord_oj.cuda()\n","        # self.coord_oi = Variable(self.coord_oi)\n","        # self.coord_oj = Variable(self.coord_oj)\n","\n","        # prepare coord tensor\n","        def cvt_coord(i):\n","            return [(i/5-2)/2., (i%5-2)/2.]\n","        \n","        self.coord_tensor = torch.FloatTensor(kwargs['batch_size'], 25, 2)\n","        if kwargs['cuda']:\n","            self.coord_tensor = self.coord_tensor.cuda()\n","        # self.coord_tensor = Variable(self.coord_tensor)\n","        np_coord_tensor = np.zeros((kwargs['batch_size'], 25, 2))\n","        for i in range(25):\n","            np_coord_tensor[:,i,:] = np.array( cvt_coord(i) )\n","        self.coord_tensor.data.copy_(torch.from_numpy(np_coord_tensor))\n","\n","\n","        self.fcout = FCOutputModel()\n","        \n","        self.optimizer = optim.Adam(self.parameters(), lr=kwargs['lr'])\n","\n","\n","    def forward(self, img, qst):\n","        x = self.conv(img) ## x = (64 x 256 x 5 x 5)\n","        \"\"\"g\"\"\"\n","        mb = x.size()[0]\n","        n_channels = x.size()[1]\n","        d = x.size()[2]\n","        \n","        x_flat = x.view(mb, n_channels, d * d).permute(0, 2, 1) # (64 x 25 x 256)\n","        x_flat = torch.cat([x_flat, self.coord_tensor], 2) # (64 x 25 x 256+2)\n","\n","        # add question everywhere\n","        qst = torch.unsqueeze(qst, 1) # (64 x 1 x 18)\n","        qst = qst.repeat(1, 25, 1) # (64 x 25 x 18)\n","        qst = torch.unsqueeze(qst, 2) # (64 x 25 x 1 x 18)\n","        \n","        # cast all pairs against each other\n","        x_i = torch.unsqueeze(x_flat, 1)  # (64 x 1 x 25 x 258)\n","        x_i = x_i.repeat(1, 25, 1, 1)  # (64 x 25 x 25 x 258)\n","        x_j = torch.unsqueeze(x_flat, 2)  # (64 x 25 x 1 x 258)\n","        x_j = torch.cat([x_j, qst], 3) # (64 x 25 x 1 x 258+18)\n","        x_j = x_j.repeat(1, 1, 25, 1) # (64 x 25 x 25 x 276)\n","        \n","        # concatenate all together\n","        x_full = torch.cat([x_i,x_j],3) # (64 x 25 x 25 x 258+276)\n","    \n","        # reshape for passing through network\n","        x_ = x_full.view(mb * (d * d) * (d * d), 534)  # (64 x 25 x 25 x 534) = (40000, 534)\n","         \n","        \"\"\"g\"\"\"\n","        x_ = self.g_fc1(x_) # (40000, 2000)\n","        x_ = F.relu(x_)\n","        x_ = self.g_fc2(x_) # (40000, 2000)\n","        x_ = F.relu(x_)\n","        x_ = self.g_fc3(x_) # (40000, 2000)\n","        x_ = F.relu(x_)\n","        x_ = self.g_fc4(x_) # (40000, 2000)\n","        x_ = F.relu(x_)\n","\n","        # reshape again and sum\n","        if self.relation_type == 'ternary':\n","            x_g = x_.view(mb, (d * d) * (d * d) * (d * d), 2000)\n","        else:\n","            x_g = x_.view(mb, (d * d) * (d * d), 2000)\n","        x_g = x_g.sum(1).squeeze()\n","\n","        \"\"\"f\"\"\"\n","        x_f = self.f_fc1(x_g) # (64, 2000)\n","        x_f = F.relu(x_f)\n","        x_f = self.f_fc2(x_f) # (64, 1000)\n","        x_f = F.relu(x_f)\n","        x_f = self.f_fc3(x_f) # (64, 500)\n","        x_f = F.relu(x_f)\n","        x_f = self.f_fc4(x_f) # (64, 100)\n","        x_f = F.relu(x_f)\n","        \n","        return self.fcout(x_f)"],"metadata":{"id":"ynUC1Uzk56Xo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Functions"],"metadata":{"id":"qZ8vE4R11Vn6"}},{"cell_type":"code","source":["summary_writer = SummaryWriter()"],"metadata":{"id":"CRZ6heQb6OZP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def tensor_data(data, i):\n","    img = torch.from_numpy(np.asarray(data[0][bs*i:bs*(i+1)]))\n","    qst = torch.from_numpy(np.asarray(data[1][bs*i:bs*(i+1)]))\n","    ans = torch.from_numpy(np.asarray(data[2][bs*i:bs*(i+1)]))\n","\n","    input_img.data.resize_(img.size()).copy_(img)\n","    input_qst.data.resize_(qst.size()).copy_(qst)\n","    label.data.resize_(ans.size()).copy_(ans)"],"metadata":{"id":"RnWfm_RbFK9s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def cvt_data_axis(data):\n","    img = [e[0] for e in data]\n","    qst = [e[1] for e in data]\n","    ans = [e[2] for e in data]\n","    return (img,qst,ans)"],"metadata":{"id":"iNq-z9cVFl6j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(epoch, ternary, rel, norel):\n","    model.train()\n","\n","    if not len(rel[0]) == len(norel[0]):\n","        print('Not equal length for relation dataset and non-relation dataset.')\n","        return\n","    \n","    random.shuffle(ternary)\n","    random.shuffle(rel)\n","    random.shuffle(norel)\n","\n","    ternary = cvt_data_axis(ternary)\n","    rel = cvt_data_axis(rel)\n","    norel = cvt_data_axis(norel)\n","\n","    acc_ternary = []\n","    acc_rels = []\n","    acc_norels = []\n","\n","    l_ternary = []\n","    l_binary = []\n","    l_unary = []\n","\n","    for batch_idx in range(len(rel[0]) // bs):\n","        tensor_data(ternary, batch_idx)\n","        accuracy_ternary, loss_ternary = model.train_(input_img, input_qst, label)\n","        acc_ternary.append(accuracy_ternary.item())\n","        l_ternary.append(loss_ternary.item())\n","\n","        tensor_data(rel, batch_idx)\n","        accuracy_rel, loss_binary = model.train_(input_img, input_qst, label)\n","        acc_rels.append(accuracy_rel.item())\n","        l_binary.append(loss_binary.item())\n","\n","        tensor_data(norel, batch_idx)\n","        accuracy_norel, loss_unary = model.train_(input_img, input_qst, label)\n","        acc_norels.append(accuracy_norel.item())\n","        l_unary.append(loss_unary.item())\n","\n","        if batch_idx % log_interval == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)] '\n","                  'Ternary accuracy: {:.0f}% | Relations accuracy: {:.0f}% | Non-relations accuracy: {:.0f}%'.format(\n","                   epoch,\n","                   batch_idx * bs * 2,\n","                   len(rel[0]) * 2,\n","                   100. * batch_idx * bs / len(rel[0]),\n","                   accuracy_ternary,\n","                   accuracy_rel,\n","                   accuracy_norel))\n","        \n","    avg_acc_ternary = sum(acc_ternary) / len(acc_ternary)\n","    avg_acc_binary = sum(acc_rels) / len(acc_rels)\n","    avg_acc_unary = sum(acc_norels) / len(acc_norels)\n","\n","    summary_writer.add_scalars('Accuracy/train', {\n","        'ternary': avg_acc_ternary,\n","        'binary': avg_acc_binary,\n","        'unary': avg_acc_unary\n","    }, epoch)\n","\n","    avg_loss_ternary = sum(l_ternary) / len(l_ternary)\n","    avg_loss_binary = sum(l_binary) / len(l_binary)\n","    avg_loss_unary = sum(l_unary) / len(l_unary)\n","\n","    summary_writer.add_scalars('Loss/train', {\n","        'ternary': avg_loss_ternary,\n","        'binary': avg_loss_binary,\n","        'unary': avg_loss_unary\n","    }, epoch)\n","\n","    # return average accuracy\n","    return avg_acc_ternary, avg_acc_binary, avg_acc_unary\n"],"metadata":{"id":"LgCa30KdFnUL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def test(epoch, ternary, rel, norel):\n","    model.eval()\n","    if not len(rel[0]) == len(norel[0]):\n","        print('Not equal length for relation dataset and non-relation dataset.')\n","        return\n","    \n","    ternary = cvt_data_axis(ternary)\n","    rel = cvt_data_axis(rel)\n","    norel = cvt_data_axis(norel)\n","\n","    accuracy_ternary = []\n","    accuracy_rels = []\n","    accuracy_norels = []\n","\n","    loss_ternary = []\n","    loss_binary = []\n","    loss_unary = []\n","\n","    for batch_idx in range(len(rel[0]) // bs):\n","        tensor_data(ternary, batch_idx)\n","        acc_ter, l_ter = model.test_(input_img, input_qst, label)\n","        accuracy_ternary.append(acc_ter.item())\n","        loss_ternary.append(l_ter.item())\n","\n","        tensor_data(rel, batch_idx)\n","        acc_bin, l_bin = model.test_(input_img, input_qst, label)\n","        accuracy_rels.append(acc_bin.item())\n","        loss_binary.append(l_bin.item())\n","\n","        tensor_data(norel, batch_idx)\n","        acc_un, l_un = model.test_(input_img, input_qst, label)\n","        accuracy_norels.append(acc_un.item())\n","        loss_unary.append(l_un.item())\n","\n","    accuracy_ternary = sum(accuracy_ternary) / len(accuracy_ternary)\n","    accuracy_rel = sum(accuracy_rels) / len(accuracy_rels)\n","    accuracy_norel = sum(accuracy_norels) / len(accuracy_norels)\n","    print('\\n Test set: Ternary accuracy: {:.0f}% Binary accuracy: {:.0f}% | Unary accuracy: {:.0f}%\\n'.format(\n","        accuracy_ternary, accuracy_rel, accuracy_norel))\n","\n","    summary_writer.add_scalars('Accuracy/test', {\n","        'ternary': accuracy_ternary,\n","        'binary': accuracy_rel,\n","        'unary': accuracy_norel\n","    }, epoch)\n","\n","    loss_ternary = sum(loss_ternary) / len(loss_ternary)\n","    loss_binary = sum(loss_binary) / len(loss_binary)\n","    loss_unary = sum(loss_unary) / len(loss_unary)\n","\n","    summary_writer.add_scalars('Loss/test', {\n","        'ternary': loss_ternary,\n","        'binary': loss_binary,\n","        'unary': loss_unary\n","    }, epoch)\n","\n","    return accuracy_ternary, accuracy_rel, accuracy_norel"],"metadata":{"id":"YUVPPcJNFpeU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_data():\n","    print('loading data...')\n","    dirs = './data'\n","    filename = os.path.join(dirs,'sort-of-clevr.pickle')\n","    with open(filename, 'rb') as f:\n","      train_datasets, test_datasets = pickle.load(f)\n","    ternary_train = []\n","    ternary_test = []\n","    rel_train = []\n","    rel_test = []\n","    norel_train = []\n","    norel_test = []\n","    print('processing data...')\n","\n","    for img, ternary, relations, norelations in train_datasets:\n","        img = np.swapaxes(img, 0, 2)\n","        for qst, ans in zip(ternary[0], ternary[1]):\n","            ternary_train.append((img,qst,ans))\n","        for qst,ans in zip(relations[0], relations[1]):\n","            rel_train.append((img,qst,ans))\n","        for qst,ans in zip(norelations[0], norelations[1]):\n","            norel_train.append((img,qst,ans))\n","\n","    for img, ternary, relations, norelations in test_datasets:\n","        img = np.swapaxes(img, 0, 2)\n","        for qst, ans in zip(ternary[0], ternary[1]):\n","            ternary_test.append((img, qst, ans))\n","        for qst,ans in zip(relations[0], relations[1]):\n","            rel_test.append((img,qst,ans))\n","        for qst,ans in zip(norelations[0], norelations[1]):\n","            norel_test.append((img,qst,ans))\n","    \n","    return (ternary_train, ternary_test, rel_train, rel_test, norel_train, norel_test)"],"metadata":{"id":"cEeMCIBqFrVc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 1.2 Load Dataset"],"metadata":{"id":"peiU8jSG0l5G"}},{"cell_type":"code","source":["ternary_train, ternary_test, rel_train, rel_test, norel_train, norel_test = load_data()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JZ36_lx-Fuf_","executionInfo":{"status":"ok","timestamp":1670414488830,"user_tz":300,"elapsed":7115,"user":{"displayName":"Faiz Andrea Ganz","userId":"07639753498586550069"}},"outputId":"99f9990a-7226-4243-ef52-51d312a8984f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["loading data...\n","processing data...\n"]}]},{"cell_type":"markdown","source":["### 1.3 Instanciates Model"],"metadata":{"id":"DGGgE8eF0tgN"}},{"cell_type":"code","source":["kwargs = {\n","    'relation_type': 'binary',\n","    'batch_size': 64,\n","    'cuda': True,\n","    'lr': 1e-4,\n","}\n","    \n","model = RN(**kwargs)\n","model"],"metadata":{"id":"lyq7IiMg8lf0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670414502787,"user_tz":300,"elapsed":6437,"user":{"displayName":"Faiz Andrea Ganz","userId":"07639753498586550069"}},"outputId":"cc802518-5353-4452-f67c-fcb5231c7c00"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RN(\n","  (conv): ConvInputModel(\n","    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (batchNorm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (batchNorm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (batchNorm3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (batchNorm4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (g_fc1): Linear(in_features=534, out_features=2000, bias=True)\n","  (g_fc2): Linear(in_features=2000, out_features=2000, bias=True)\n","  (g_fc3): Linear(in_features=2000, out_features=2000, bias=True)\n","  (g_fc4): Linear(in_features=2000, out_features=2000, bias=True)\n","  (f_fc1): Linear(in_features=2000, out_features=2000, bias=True)\n","  (f_fc2): Linear(in_features=2000, out_features=1000, bias=True)\n","  (f_fc3): Linear(in_features=1000, out_features=500, bias=True)\n","  (f_fc4): Linear(in_features=500, out_features=100, bias=True)\n","  (fcout): FCOutputModel(\n","    (fc2): Linear(in_features=100, out_features=100, bias=True)\n","    (fc3): Linear(in_features=100, out_features=10, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["model_dirs = './model'\n","bs = kwargs['batch_size']\n","input_img = torch.FloatTensor(bs, 3, 75, 75)\n","input_qst = torch.FloatTensor(bs, 18)\n","label = torch.LongTensor(bs)"],"metadata":{"id":"NdhRnPAeEP9_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if kwargs['cuda']:\n","    model.cuda()\n","    input_img = input_img.cuda()\n","    input_qst = input_qst.cuda()\n","    label = label.cuda()"],"metadata":{"id":"VZfGkSYDFF-0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 1.4 Train Model"],"metadata":{"id":"gaqJWtfc1EWh"}},{"cell_type":"code","source":["try:\n","    os.makedirs(model_dirs)\n","except:\n","    print('directory {} already exists'.format(model_dirs))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pKWT8SxKGEuy","executionInfo":{"status":"ok","timestamp":1670414507098,"user_tz":300,"elapsed":2,"user":{"displayName":"Faiz Andrea Ganz","userId":"07639753498586550069"}},"outputId":"534d598f-ac13-4887-dbc6-7d093795b10e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["directory ./model already exists\n"]}]},{"cell_type":"code","source":["epochs = 20\n","model_type = 'RN'\n","seed = 1\n","log_interval = 300"],"metadata":{"id":"bw9RKOfbGq_N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(f'./{model_type}_{seed}_log.csv', 'w') as log_file:\n","    csv_writer = csv.writer(log_file, delimiter=',')\n","    csv_writer.writerow(['epoch', 'train_acc_ternary', 'train_acc_rel',\n","                     'train_acc_norel', 'train_acc_ternary', 'test_acc_rel', 'test_acc_norel'])\n","\n","    # print(\"Training {} {}\" if model_type == 'RN' else ''} model...\")\n","    print('Training...')\n","\n","    for epoch in range(1, epochs + 1):\n","        train_acc_ternary, train_acc_binary, train_acc_unary = train(\n","            epoch, ternary_train, rel_train, norel_train)\n","        test_acc_ternary, test_acc_binary, test_acc_unary = test(\n","            epoch, ternary_test, rel_test, norel_test)\n","\n","        csv_writer.writerow([epoch, train_acc_ternary, train_acc_binary,\n","                         train_acc_unary, test_acc_ternary, test_acc_binary, test_acc_unary])\n","        model.save_model(epoch)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_84riuo8GkAi","outputId":"6fd40855-2169-4799-b1d0-2791e642b7cc","executionInfo":{"status":"ok","timestamp":1670432124701,"user_tz":300,"elapsed":15757028,"user":{"displayName":"Faiz Andrea Ganz","userId":"07639753498586550069"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training...\n","Train Epoch: 1 [0/196000 (0%)] Ternary accuracy: 9% | Relations accuracy: 2% | Non-relations accuracy: 9%\n","Train Epoch: 1 [38400/196000 (20%)] Ternary accuracy: 38% | Relations accuracy: 56% | Non-relations accuracy: 56%\n","Train Epoch: 1 [76800/196000 (39%)] Ternary accuracy: 50% | Relations accuracy: 48% | Non-relations accuracy: 58%\n","Train Epoch: 1 [115200/196000 (59%)] Ternary accuracy: 39% | Relations accuracy: 45% | Non-relations accuracy: 48%\n","Train Epoch: 1 [153600/196000 (78%)] Ternary accuracy: 64% | Relations accuracy: 47% | Non-relations accuracy: 58%\n","Train Epoch: 1 [192000/196000 (98%)] Ternary accuracy: 50% | Relations accuracy: 45% | Non-relations accuracy: 47%\n","\n"," Test set: Ternary accuracy: 53% Binary accuracy: 43% | Unary accuracy: 52%\n","\n","Train Epoch: 2 [0/196000 (0%)] Ternary accuracy: 50% | Relations accuracy: 50% | Non-relations accuracy: 52%\n","Train Epoch: 2 [38400/196000 (20%)] Ternary accuracy: 56% | Relations accuracy: 41% | Non-relations accuracy: 47%\n","Train Epoch: 2 [76800/196000 (39%)] Ternary accuracy: 62% | Relations accuracy: 44% | Non-relations accuracy: 48%\n","Train Epoch: 2 [115200/196000 (59%)] Ternary accuracy: 50% | Relations accuracy: 44% | Non-relations accuracy: 56%\n","Train Epoch: 2 [153600/196000 (78%)] Ternary accuracy: 47% | Relations accuracy: 39% | Non-relations accuracy: 48%\n","Train Epoch: 2 [192000/196000 (98%)] Ternary accuracy: 50% | Relations accuracy: 39% | Non-relations accuracy: 47%\n","\n"," Test set: Ternary accuracy: 54% Binary accuracy: 42% | Unary accuracy: 51%\n","\n","Train Epoch: 3 [0/196000 (0%)] Ternary accuracy: 50% | Relations accuracy: 50% | Non-relations accuracy: 56%\n","Train Epoch: 3 [38400/196000 (20%)] Ternary accuracy: 47% | Relations accuracy: 47% | Non-relations accuracy: 53%\n","Train Epoch: 3 [76800/196000 (39%)] Ternary accuracy: 50% | Relations accuracy: 44% | Non-relations accuracy: 59%\n","Train Epoch: 3 [115200/196000 (59%)] Ternary accuracy: 50% | Relations accuracy: 48% | Non-relations accuracy: 45%\n","Train Epoch: 3 [153600/196000 (78%)] Ternary accuracy: 48% | Relations accuracy: 44% | Non-relations accuracy: 58%\n","Train Epoch: 3 [192000/196000 (98%)] Ternary accuracy: 53% | Relations accuracy: 42% | Non-relations accuracy: 38%\n","\n"," Test set: Ternary accuracy: 53% Binary accuracy: 42% | Unary accuracy: 47%\n","\n","Train Epoch: 4 [0/196000 (0%)] Ternary accuracy: 56% | Relations accuracy: 42% | Non-relations accuracy: 42%\n","Train Epoch: 4 [38400/196000 (20%)] Ternary accuracy: 56% | Relations accuracy: 33% | Non-relations accuracy: 45%\n","Train Epoch: 4 [76800/196000 (39%)] Ternary accuracy: 66% | Relations accuracy: 50% | Non-relations accuracy: 53%\n","Train Epoch: 4 [115200/196000 (59%)] Ternary accuracy: 56% | Relations accuracy: 52% | Non-relations accuracy: 44%\n","Train Epoch: 4 [153600/196000 (78%)] Ternary accuracy: 62% | Relations accuracy: 41% | Non-relations accuracy: 53%\n","Train Epoch: 4 [192000/196000 (98%)] Ternary accuracy: 53% | Relations accuracy: 50% | Non-relations accuracy: 48%\n","\n"," Test set: Ternary accuracy: 52% Binary accuracy: 43% | Unary accuracy: 49%\n","\n","Train Epoch: 5 [0/196000 (0%)] Ternary accuracy: 48% | Relations accuracy: 41% | Non-relations accuracy: 56%\n","Train Epoch: 5 [38400/196000 (20%)] Ternary accuracy: 48% | Relations accuracy: 38% | Non-relations accuracy: 39%\n","Train Epoch: 5 [76800/196000 (39%)] Ternary accuracy: 62% | Relations accuracy: 45% | Non-relations accuracy: 53%\n","Train Epoch: 5 [115200/196000 (59%)] Ternary accuracy: 52% | Relations accuracy: 48% | Non-relations accuracy: 48%\n","Train Epoch: 5 [153600/196000 (78%)] Ternary accuracy: 58% | Relations accuracy: 34% | Non-relations accuracy: 56%\n","Train Epoch: 5 [192000/196000 (98%)] Ternary accuracy: 56% | Relations accuracy: 47% | Non-relations accuracy: 56%\n","\n"," Test set: Ternary accuracy: 53% Binary accuracy: 45% | Unary accuracy: 51%\n","\n","Train Epoch: 6 [0/196000 (0%)] Ternary accuracy: 52% | Relations accuracy: 42% | Non-relations accuracy: 58%\n","Train Epoch: 6 [38400/196000 (20%)] Ternary accuracy: 50% | Relations accuracy: 36% | Non-relations accuracy: 50%\n","Train Epoch: 6 [76800/196000 (39%)] Ternary accuracy: 52% | Relations accuracy: 55% | Non-relations accuracy: 53%\n","Train Epoch: 6 [115200/196000 (59%)] Ternary accuracy: 72% | Relations accuracy: 45% | Non-relations accuracy: 55%\n","Train Epoch: 6 [153600/196000 (78%)] Ternary accuracy: 55% | Relations accuracy: 36% | Non-relations accuracy: 55%\n","Train Epoch: 6 [192000/196000 (98%)] Ternary accuracy: 50% | Relations accuracy: 39% | Non-relations accuracy: 61%\n","\n"," Test set: Ternary accuracy: 54% Binary accuracy: 42% | Unary accuracy: 55%\n","\n","Train Epoch: 7 [0/196000 (0%)] Ternary accuracy: 56% | Relations accuracy: 36% | Non-relations accuracy: 53%\n","Train Epoch: 7 [38400/196000 (20%)] Ternary accuracy: 58% | Relations accuracy: 41% | Non-relations accuracy: 50%\n","Train Epoch: 7 [76800/196000 (39%)] Ternary accuracy: 67% | Relations accuracy: 56% | Non-relations accuracy: 47%\n","Train Epoch: 7 [115200/196000 (59%)] Ternary accuracy: 52% | Relations accuracy: 28% | Non-relations accuracy: 77%\n","Train Epoch: 7 [153600/196000 (78%)] Ternary accuracy: 41% | Relations accuracy: 48% | Non-relations accuracy: 48%\n","Train Epoch: 7 [192000/196000 (98%)] Ternary accuracy: 56% | Relations accuracy: 42% | Non-relations accuracy: 62%\n","\n"," Test set: Ternary accuracy: 55% Binary accuracy: 41% | Unary accuracy: 59%\n","\n","Train Epoch: 8 [0/196000 (0%)] Ternary accuracy: 44% | Relations accuracy: 52% | Non-relations accuracy: 62%\n","Train Epoch: 8 [38400/196000 (20%)] Ternary accuracy: 52% | Relations accuracy: 45% | Non-relations accuracy: 72%\n","Train Epoch: 8 [76800/196000 (39%)] Ternary accuracy: 47% | Relations accuracy: 39% | Non-relations accuracy: 64%\n","Train Epoch: 8 [115200/196000 (59%)] Ternary accuracy: 66% | Relations accuracy: 48% | Non-relations accuracy: 73%\n","Train Epoch: 8 [153600/196000 (78%)] Ternary accuracy: 52% | Relations accuracy: 41% | Non-relations accuracy: 72%\n","Train Epoch: 8 [192000/196000 (98%)] Ternary accuracy: 56% | Relations accuracy: 53% | Non-relations accuracy: 80%\n","\n"," Test set: Ternary accuracy: 53% Binary accuracy: 48% | Unary accuracy: 78%\n","\n","Train Epoch: 9 [0/196000 (0%)] Ternary accuracy: 59% | Relations accuracy: 45% | Non-relations accuracy: 84%\n","Train Epoch: 9 [38400/196000 (20%)] Ternary accuracy: 59% | Relations accuracy: 53% | Non-relations accuracy: 94%\n","Train Epoch: 9 [76800/196000 (39%)] Ternary accuracy: 59% | Relations accuracy: 56% | Non-relations accuracy: 88%\n","Train Epoch: 9 [115200/196000 (59%)] Ternary accuracy: 59% | Relations accuracy: 55% | Non-relations accuracy: 92%\n","Train Epoch: 9 [153600/196000 (78%)] Ternary accuracy: 58% | Relations accuracy: 56% | Non-relations accuracy: 94%\n","Train Epoch: 9 [192000/196000 (98%)] Ternary accuracy: 55% | Relations accuracy: 64% | Non-relations accuracy: 92%\n","\n"," Test set: Ternary accuracy: 54% Binary accuracy: 51% | Unary accuracy: 95%\n","\n","Train Epoch: 10 [0/196000 (0%)] Ternary accuracy: 59% | Relations accuracy: 48% | Non-relations accuracy: 94%\n","Train Epoch: 10 [38400/196000 (20%)] Ternary accuracy: 59% | Relations accuracy: 56% | Non-relations accuracy: 91%\n","Train Epoch: 10 [76800/196000 (39%)] Ternary accuracy: 56% | Relations accuracy: 56% | Non-relations accuracy: 97%\n","Train Epoch: 10 [115200/196000 (59%)] Ternary accuracy: 52% | Relations accuracy: 64% | Non-relations accuracy: 95%\n","Train Epoch: 10 [153600/196000 (78%)] Ternary accuracy: 52% | Relations accuracy: 69% | Non-relations accuracy: 100%\n","Train Epoch: 10 [192000/196000 (98%)] Ternary accuracy: 52% | Relations accuracy: 59% | Non-relations accuracy: 100%\n","\n"," Test set: Ternary accuracy: 55% Binary accuracy: 68% | Unary accuracy: 98%\n","\n","Train Epoch: 11 [0/196000 (0%)] Ternary accuracy: 56% | Relations accuracy: 58% | Non-relations accuracy: 98%\n","Train Epoch: 11 [38400/196000 (20%)] Ternary accuracy: 56% | Relations accuracy: 73% | Non-relations accuracy: 100%\n","Train Epoch: 11 [76800/196000 (39%)] Ternary accuracy: 58% | Relations accuracy: 70% | Non-relations accuracy: 100%\n","Train Epoch: 11 [115200/196000 (59%)] Ternary accuracy: 59% | Relations accuracy: 64% | Non-relations accuracy: 100%\n","Train Epoch: 11 [153600/196000 (78%)] Ternary accuracy: 58% | Relations accuracy: 69% | Non-relations accuracy: 100%\n","Train Epoch: 11 [192000/196000 (98%)] Ternary accuracy: 48% | Relations accuracy: 80% | Non-relations accuracy: 100%\n","\n"," Test set: Ternary accuracy: 55% Binary accuracy: 79% | Unary accuracy: 99%\n","\n","Train Epoch: 12 [0/196000 (0%)] Ternary accuracy: 50% | Relations accuracy: 77% | Non-relations accuracy: 98%\n","Train Epoch: 12 [38400/196000 (20%)] Ternary accuracy: 61% | Relations accuracy: 86% | Non-relations accuracy: 100%\n","Train Epoch: 12 [76800/196000 (39%)] Ternary accuracy: 47% | Relations accuracy: 77% | Non-relations accuracy: 100%\n","Train Epoch: 12 [115200/196000 (59%)] Ternary accuracy: 53% | Relations accuracy: 78% | Non-relations accuracy: 100%\n","Train Epoch: 12 [153600/196000 (78%)] Ternary accuracy: 58% | Relations accuracy: 78% | Non-relations accuracy: 100%\n","Train Epoch: 12 [192000/196000 (98%)] Ternary accuracy: 61% | Relations accuracy: 72% | Non-relations accuracy: 100%\n","\n"," Test set: Ternary accuracy: 56% Binary accuracy: 80% | Unary accuracy: 99%\n","\n","Train Epoch: 13 [0/196000 (0%)] Ternary accuracy: 64% | Relations accuracy: 75% | Non-relations accuracy: 100%\n","Train Epoch: 13 [38400/196000 (20%)] Ternary accuracy: 52% | Relations accuracy: 73% | Non-relations accuracy: 100%\n","Train Epoch: 13 [76800/196000 (39%)] Ternary accuracy: 62% | Relations accuracy: 75% | Non-relations accuracy: 100%\n","Train Epoch: 13 [115200/196000 (59%)] Ternary accuracy: 55% | Relations accuracy: 78% | Non-relations accuracy: 100%\n","Train Epoch: 13 [153600/196000 (78%)] Ternary accuracy: 53% | Relations accuracy: 80% | Non-relations accuracy: 100%\n","Train Epoch: 13 [192000/196000 (98%)] Ternary accuracy: 58% | Relations accuracy: 86% | Non-relations accuracy: 98%\n","\n"," Test set: Ternary accuracy: 56% Binary accuracy: 79% | Unary accuracy: 99%\n","\n","Train Epoch: 14 [0/196000 (0%)] Ternary accuracy: 58% | Relations accuracy: 81% | Non-relations accuracy: 100%\n","Train Epoch: 14 [38400/196000 (20%)] Ternary accuracy: 52% | Relations accuracy: 86% | Non-relations accuracy: 98%\n","Train Epoch: 14 [76800/196000 (39%)] Ternary accuracy: 58% | Relations accuracy: 84% | Non-relations accuracy: 100%\n","Train Epoch: 14 [115200/196000 (59%)] Ternary accuracy: 62% | Relations accuracy: 89% | Non-relations accuracy: 100%\n","Train Epoch: 14 [153600/196000 (78%)] Ternary accuracy: 67% | Relations accuracy: 86% | Non-relations accuracy: 98%\n","Train Epoch: 14 [192000/196000 (98%)] Ternary accuracy: 64% | Relations accuracy: 91% | Non-relations accuracy: 98%\n","\n"," Test set: Ternary accuracy: 57% Binary accuracy: 84% | Unary accuracy: 99%\n","\n","Train Epoch: 15 [0/196000 (0%)] Ternary accuracy: 56% | Relations accuracy: 88% | Non-relations accuracy: 100%\n","Train Epoch: 15 [38400/196000 (20%)] Ternary accuracy: 67% | Relations accuracy: 75% | Non-relations accuracy: 100%\n","Train Epoch: 15 [76800/196000 (39%)] Ternary accuracy: 58% | Relations accuracy: 89% | Non-relations accuracy: 98%\n","Train Epoch: 15 [115200/196000 (59%)] Ternary accuracy: 56% | Relations accuracy: 80% | Non-relations accuracy: 98%\n","Train Epoch: 15 [153600/196000 (78%)] Ternary accuracy: 69% | Relations accuracy: 88% | Non-relations accuracy: 100%\n","Train Epoch: 15 [192000/196000 (98%)] Ternary accuracy: 55% | Relations accuracy: 89% | Non-relations accuracy: 100%\n","\n"," Test set: Ternary accuracy: 60% Binary accuracy: 86% | Unary accuracy: 100%\n","\n","Train Epoch: 16 [0/196000 (0%)] Ternary accuracy: 72% | Relations accuracy: 94% | Non-relations accuracy: 100%\n","Train Epoch: 16 [38400/196000 (20%)] Ternary accuracy: 55% | Relations accuracy: 88% | Non-relations accuracy: 100%\n","Train Epoch: 16 [76800/196000 (39%)] Ternary accuracy: 59% | Relations accuracy: 92% | Non-relations accuracy: 100%\n","Train Epoch: 16 [115200/196000 (59%)] Ternary accuracy: 73% | Relations accuracy: 89% | Non-relations accuracy: 98%\n","Train Epoch: 16 [153600/196000 (78%)] Ternary accuracy: 50% | Relations accuracy: 88% | Non-relations accuracy: 98%\n","Train Epoch: 16 [192000/196000 (98%)] Ternary accuracy: 70% | Relations accuracy: 91% | Non-relations accuracy: 100%\n","\n"," Test set: Ternary accuracy: 62% Binary accuracy: 87% | Unary accuracy: 99%\n","\n","Train Epoch: 17 [0/196000 (0%)] Ternary accuracy: 70% | Relations accuracy: 91% | Non-relations accuracy: 100%\n","Train Epoch: 17 [38400/196000 (20%)] Ternary accuracy: 64% | Relations accuracy: 94% | Non-relations accuracy: 100%\n","Train Epoch: 17 [76800/196000 (39%)] Ternary accuracy: 62% | Relations accuracy: 81% | Non-relations accuracy: 98%\n","Train Epoch: 17 [115200/196000 (59%)] Ternary accuracy: 66% | Relations accuracy: 92% | Non-relations accuracy: 98%\n","Train Epoch: 17 [153600/196000 (78%)] Ternary accuracy: 59% | Relations accuracy: 88% | Non-relations accuracy: 100%\n","Train Epoch: 17 [192000/196000 (98%)] Ternary accuracy: 73% | Relations accuracy: 94% | Non-relations accuracy: 100%\n","\n"," Test set: Ternary accuracy: 62% Binary accuracy: 89% | Unary accuracy: 99%\n","\n","Train Epoch: 18 [0/196000 (0%)] Ternary accuracy: 53% | Relations accuracy: 91% | Non-relations accuracy: 100%\n","Train Epoch: 18 [38400/196000 (20%)] Ternary accuracy: 59% | Relations accuracy: 92% | Non-relations accuracy: 100%\n","Train Epoch: 18 [76800/196000 (39%)] Ternary accuracy: 69% | Relations accuracy: 94% | Non-relations accuracy: 100%\n","Train Epoch: 18 [115200/196000 (59%)] Ternary accuracy: 70% | Relations accuracy: 95% | Non-relations accuracy: 100%\n","Train Epoch: 18 [153600/196000 (78%)] Ternary accuracy: 64% | Relations accuracy: 94% | Non-relations accuracy: 100%\n","Train Epoch: 18 [192000/196000 (98%)] Ternary accuracy: 59% | Relations accuracy: 100% | Non-relations accuracy: 100%\n","\n"," Test set: Ternary accuracy: 66% Binary accuracy: 92% | Unary accuracy: 100%\n","\n","Train Epoch: 19 [0/196000 (0%)] Ternary accuracy: 72% | Relations accuracy: 97% | Non-relations accuracy: 98%\n","Train Epoch: 19 [38400/196000 (20%)] Ternary accuracy: 62% | Relations accuracy: 95% | Non-relations accuracy: 100%\n","Train Epoch: 19 [76800/196000 (39%)] Ternary accuracy: 66% | Relations accuracy: 97% | Non-relations accuracy: 100%\n","Train Epoch: 19 [115200/196000 (59%)] Ternary accuracy: 55% | Relations accuracy: 97% | Non-relations accuracy: 100%\n","Train Epoch: 19 [153600/196000 (78%)] Ternary accuracy: 69% | Relations accuracy: 95% | Non-relations accuracy: 100%\n","Train Epoch: 19 [192000/196000 (98%)] Ternary accuracy: 66% | Relations accuracy: 95% | Non-relations accuracy: 98%\n","\n"," Test set: Ternary accuracy: 65% Binary accuracy: 91% | Unary accuracy: 99%\n","\n","Train Epoch: 20 [0/196000 (0%)] Ternary accuracy: 72% | Relations accuracy: 91% | Non-relations accuracy: 100%\n","Train Epoch: 20 [38400/196000 (20%)] Ternary accuracy: 75% | Relations accuracy: 97% | Non-relations accuracy: 100%\n","Train Epoch: 20 [76800/196000 (39%)] Ternary accuracy: 66% | Relations accuracy: 94% | Non-relations accuracy: 100%\n","Train Epoch: 20 [115200/196000 (59%)] Ternary accuracy: 66% | Relations accuracy: 97% | Non-relations accuracy: 100%\n","Train Epoch: 20 [153600/196000 (78%)] Ternary accuracy: 69% | Relations accuracy: 95% | Non-relations accuracy: 100%\n","Train Epoch: 20 [192000/196000 (98%)] Ternary accuracy: 70% | Relations accuracy: 97% | Non-relations accuracy: 100%\n","\n"," Test set: Ternary accuracy: 65% Binary accuracy: 91% | Unary accuracy: 100%\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"anFsM4hndp7y"},"execution_count":null,"outputs":[]}]}